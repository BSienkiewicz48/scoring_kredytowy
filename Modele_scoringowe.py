import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from category_encoders.woe import WOEEncoder
from sklearn.preprocessing import KBinsDiscretizer
from optbinning import OptimalBinning
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score, roc_curve, mean_absolute_error
import xgboost as xgb

# Funkcja czyszczƒÖca dane
def clean_data(df):
    df['kwota_kredytu'] = df['kwota_kredytu'].replace('[\$,]', '', regex=True).astype(float)
    for col in ['oproc_refin', 'oproc_konkur', 'koszt_pieniadza', 'oproc_propon']:
        # Ensure column is string, replace '%', then convert to numeric, coercing errors
        df[col] = pd.to_numeric(df[col].astype(str).str.replace('%', '', regex=False), errors='coerce')
    df['data_akceptacji'] = pd.to_datetime(df['data_akceptacji'], dayfirst=True).dt.date
    return df

# Tytu≈Ç aplikacji
st.title("üìä Scoring kredytowy ‚Äì eksploracja danych")

st.markdown("Celem tego narzƒôdzia jest przewidywanie, czy dany klient zaakceptuje przedstawionƒÖ ofertƒô kredytowƒÖ. Model zwraca wynik punktowy ‚Äì im wy≈ºszy wynik, tym wiƒôksze prawdopodobie≈Ñstwo, ≈ºe klient skorzysta z oferty. ")

# Funkcja do wczytania i przygotowania danych z cache
@st.cache_data
def load_and_clean_data():
  df = pd.read_excel("kredyty_auto_Scoring2025s.xlsx")
  df = clean_data(df)
  return df

# Wczytanie danych z wykorzystaniem cache
df = load_and_clean_data()

# Wy≈õwietlanie danych
st.subheader("üìå PodglƒÖd danych")
st.dataframe(df.drop(columns=['LP']), height=400, use_container_width=True, hide_index=True)

st.subheader("üîç Informacje o danych")
st.markdown("""
- **LP** ‚Äì numer porzƒÖdkowy wiersza.  
- **data_akceptacji** ‚Äì data akceptacji wniosku kredytowego przez bank.  
- **grupa_ryzyka** ‚Äì oznaczenie grupy ryzyka kredytowego klienta wed≈Çug klasyfikacji banku.  
- **kod_partnera** ‚Äì identyfikator partnera biznesowego (sieci dealer√≥w samochodowych).  
- **typ_umowy** ‚Äì typ umowy:  
  - ‚ÄûN‚Äù ‚Äì nowy samoch√≥d,  
  - ‚ÄûU‚Äù ‚Äì samoch√≥d u≈ºywany,  
  - ‚ÄûR‚Äù ‚Äì refinansowanie kredytu (nowy kredyt na sp≈Çatƒô sta≈Çego).  
- **scoring_FICO** ‚Äì ocena punktowa FICO (odpowiednik polskiego scoringu BIK).  
- **okres_kredytu** ‚Äì d≈Çugo≈õƒá okresu kredytowania w miesiƒÖcach (np. 48, 72, 60).  
- **kwota_kredytu** ‚Äì kwota przyznanego kredytu (np. $26,500).  
- **oproc_refin** ‚Äì oprocentowanie kredytu finansowego (dla typu umowy ‚ÄûR‚Äù).  
- **oproc_konkur** ‚Äì oprocentowanie oferowane przez konkurencjƒô (najlepsza stopa procentowa konkurenta, dane prawdopodobnie pochodzƒÖ od partner√≥w).  
- **koszt_pieniadza** ‚Äì koszt pozyskania ≈õrodk√≥w dla banku (np. 1.10%).  
- **oproc_propon** ‚Äì oprocentowanie proponowane klientowi przez bank.  
- **akceptacja_klienta** ‚Äì wynik akceptacji klienta (0 = brak akceptacji, 1 = akceptacja) - zmienna celu.  
""")

st.subheader("üìà Statystyki opisowe")
# Wyb√≥r kolumn numerycznych, kt√≥re majƒÖ sens dla statystyk opisowych
numeric_columns = ['scoring_FICO', 'okres_kredytu', 'kwota_kredytu', 
                   'oproc_refin', 'oproc_konkur', 'koszt_pieniadza', 'oproc_propon']
st.write(df[numeric_columns].describe())


st.subheader("üéª Wizualizacja wybranych zmiennych")

# Wykres violinowy dla scoring_FICO i okres_kredytu obok siebie
fig, axes = plt.subplots(1, 2, figsize=(12, 6))

# Wykres dla scoring_FICO
sns.violinplot(data=df, y='scoring_FICO', ax=axes[0], color="blue")
axes[0].set_ylabel("scoring_FICO")
axes[0].set_title("Scoring_FICO")

# Wykres dla okres_kredytu
sns.violinplot(data=df, y='okres_kredytu', ax=axes[1], color="orange")
axes[1].set_ylabel("okres_kredytu")
axes[1].set_title("Okres_kredytu")

st.pyplot(fig)

# Wykres violinowy dla oproc_refin, oproc_konkur, koszt_pieniadza, oproc_propon z wiƒôkszƒÖ wysoko≈õciƒÖ
fig2, ax2 = plt.subplots(figsize=(10, 10))
sns.violinplot(data=df[['oproc_konkur', 'koszt_pieniadza', 'oproc_propon']], ax=ax2)
ax2.set_title("Oprocentowania i koszt pieniƒÖdza")
ax2.set_ylim(0.01, 0.12)  # Ustawienie zakresu osi Y od 0 do 0.12
ax2.yaxis.set_major_locator(plt.MultipleLocator(0.005))  # Oznaczenia osi Y co 0.005
st.pyplot(fig2)

st.markdown("Wykresy violinowe okazujƒÖ nie tylko minimum, maksimum i medianƒô, ale te≈º jak ‚Äût≈Çoczno‚Äù jest w r√≥≈ºnych czƒô≈õciach rozk≈Çadu. Dziƒôki temu mo≈ºemy szybko zorientowaƒá siƒô, gdzie skupiajƒÖ siƒô obserwacje, a gdzie robi siƒô lu≈∫niej.")

# Tworzenie zmiennych pochodnych
df['spread'] = df['oproc_propon'] - df['oproc_konkur']
df['margin'] = df['oproc_propon'] - df['koszt_pieniadza']
df['rata_miesieczna'] = df['kwota_kredytu'] / df['okres_kredytu']
df['intensity_rate'] = df['rata_miesieczna'] / df['scoring_FICO']

st.markdown("""
#### ‚ú® Nowe zmienne pochodne
Na podstawie danych pierwotnych stworzono dodatkowe cechy:
- `spread` ‚Äì r√≥≈ºnica miƒôdzy oprocentowaniem banku a konkurencjƒÖ,
- `margin` ‚Äì mar≈ºa banku wzglƒôdem kosztu pozyskania ≈õrodk√≥w,
- `rata_miesieczna` ‚Äì szacunkowa wysoko≈õƒá miesiƒôcznej raty,
- `intensity_rate` ‚Äì relacja raty miesiƒôcznej do scoringu FICO (im wy≈ºsza, tym wiƒôksze ‚ÄûobciƒÖ≈ºenie‚Äù dla klienta).
""")

features_to_check = ['scoring_FICO', 'okres_kredytu', 'kwota_kredytu',
                     'oproc_refin', 'oproc_konkur', 'koszt_pieniadza', 'oproc_propon',
                     'spread', 'margin', 'rata_miesieczna', 'intensity_rate']

iv_dict = {}
binning_tables = {}

@st.cache_data
def calculate_iv_binning(df, features_to_check):
    iv_dict = {}
    binning_tables = {}

    for feature in features_to_check:
        df_temp = df[[feature, 'akceptacja_klienta']].dropna()

        # Tworzenie bin√≥w kwantylowych
        try:
            df_temp['bin'] = pd.qcut(df_temp[feature], q=10, duplicates='drop')
        except ValueError:
            df_temp['bin'] = pd.qcut(df_temp[feature], q=5, duplicates='drop')

        # Liczenie total good/bad
        total_good = (df_temp['akceptacja_klienta'] == 1).sum()
        total_bad = (df_temp['akceptacja_klienta'] == 0).sum()

        iv = 0
        table_data = []

        for name, group in df_temp.groupby('bin'):
            good = (group['akceptacja_klienta'] == 1).sum()
            bad = (group['akceptacja_klienta'] == 0).sum()

            if good > 0 and bad > 0:
                dist_good = good / total_good
                dist_bad = bad / total_bad
                woe = np.log(dist_good / dist_bad)
                iv_bin = (dist_good - dist_bad) * woe
                iv += iv_bin
            else:
                woe = 0
                iv_bin = 0

            table_data.append({
                'Przedzia≈Ç': str(name),
                'Good': good,
                'Bad': bad,
                'WOE': round(woe, 4),
                'IV_bin': round(iv_bin, 4)
            })

        iv_dict[feature] = iv
        binning_tables[feature] = pd.DataFrame(table_data)

    return iv_dict, binning_tables

iv_dict, binning_tables = calculate_iv_binning(df, features_to_check)

# Posortuj zmienne wg IV malejƒÖco
iv_series = pd.Series(iv_dict).sort_values(ascending=False)

st.subheader("üìä Si≈Ça predykcyjna zmiennych (IV)")
st.markdown("Wykres poni≈ºej pokazuje, kt√≥re zmienne najlepiej rozr√≥≈ºniajƒÖ klient√≥w, kt√≥rzy zaakceptowali ofertƒô, od tych, kt√≥rzy jej nie przyjƒôli.")

fig_iv, ax_iv = plt.subplots(figsize=(10, 6))
sns.barplot(x=iv_series.values, y=iv_series.index, palette="viridis", ax=ax_iv)
ax_iv.set_xlabel("Information Value (IV)")
ax_iv.set_ylabel("Zmienna")
ax_iv.set_title("Information value zmiennych")
st.pyplot(fig_iv)

st.markdown("""
**Interpretacja IV (Information Value):**
- < 0.02 ‚Äì brak predykcyjnej mocy  
- 0.02‚Äì0.1 ‚Äì s≈Çaba  
- 0.1‚Äì0.3 ‚Äì ≈õrednia  
- 0.3‚Äì0.5 ‚Äì silna  
- &gt; 0.5 ‚Äì bardzo silna
""")

st.subheader("üìÑ Szczeg√≥≈Çy binowania i WOE")

selected_var = st.selectbox("Wybierz zmiennƒÖ, aby zobaczyƒá tabelƒô bin√≥w:", iv_series.index.tolist())
if selected_var:
    table = binning_tables[selected_var]
    st.dataframe(table, use_container_width=True, hide_index=True)

st.markdown("""
**Opis tabeli binowania:**

Poni≈ºsza tabela przedstawia statystyki dla ka≈ºdego przedzia≈Çu (binu), na kt√≥re zosta≈Ça podzielona zmienna.  
- **Przedzia≈Ç** ‚Äì zakres warto≈õci w danym binie (ustalony metodƒÖ kwantylowƒÖ).  
- **Good / Bad** ‚Äì liczba obserwacji z klasƒÖ 1 (zaakceptowana oferta) i 0 (odmowa) w tym przedziale.  
- **WOE (Weight of Evidence)** ‚Äì miara si≈Çy rozr√≥≈ºnienia miƒôdzy klasami.  
  - Dodatnie WOE ‚Üí przewaga ‚Äûgood‚Äù  
  - Ujemne WOE ‚Üí przewaga ‚Äûbad‚Äù  
  - Im dalej od zera, tym silniejsza r√≥≈ºnicujƒÖca moc binu  
- **IV_bin** ‚Äì wk≈Çad danego binu do ca≈Çkowitego Information Value zmiennej.  
  - Im wy≈ºszy, tym wiƒôksze znaczenie danego przedzia≈Çu dla modelu.

WOE i IV sƒÖ u≈ºywane w modelach scoringowych opartych na regresji logistycznej, aby przekszta≈Çciƒá dane w bardziej informatywny i stabilny spos√≥b.
""")





@st.cache_data
def train_woe_model(df, target_col, features):
    # WOE transformacja
    encoder = WOEEncoder(cols=features)
    X = df[features]
    y = df[target_col]
    X_woe = encoder.fit_transform(X, y)

    # Podzia≈Ç na zbi√≥r treningowy i testowy (90/10)
    X_train, X_test, y_train, y_test = train_test_split(
        X_woe, y, test_size=0.1, random_state=42, stratify=y
    )

    # Regresja logistyczna
    model = LogisticRegression(max_iter=1000)
    model.fit(X_train, y_train)

    # Predykcja i ocena
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    auc = roc_auc_score(y_test, y_pred_proba)
    gini = 2 * auc - 1
    error = np.mean(np.abs(y_test - y_pred_proba)) * 100  # ≈õredni b≈ÇƒÖd procentowy

    # Scorecard (czyli tabela z predykcjami i score)
    scorecard = pd.DataFrame({
        'Prawdziwa klasa': y_test.values,
        'Prawdopodobie≈Ñstwo': np.round(y_pred_proba, 4),
        'Decyzja modelu': (y_pred_proba >= 0.5).astype(int)
    })

    return model, encoder, auc, gini, error, scorecard, X_test, y_test, y_pred_proba

# Wybierz zmienne do modelu (np. te z IV > 0.02)
features_for_model = [col for col in iv_series.index if iv_series[col] > 0.02]

st.subheader("üß™ Budowa modelu scoringowego WOE + regresja logistyczna")

st.markdown(f"""
Model zosta≈Ç wytrenowany na zbiorze treningowym z losowym podzia≈Çem 90/10.  
Wykorzystano transformacjƒô WOE na zmiennych o warto≈õci IV > 0.02.  
Wybrano {len(features_for_model)} zmiennych:  
**{', '.join(features_for_model)}**
""")

model, encoder, auc, gini, error, scorecard, X_test, y_test, y_pred_proba = train_woe_model(
    df, "akceptacja_klienta", features_for_model
)

# Metryki modelu
st.subheader("üìä Ocena modelu")
st.markdown(f"""
- **AUC**: {round(auc, 4)}  
- **Gini**: {round(gini, 4)}  
- **≈öredni b≈ÇƒÖd predykcji**: {round(error, 2)}%
""")

# Wykres ROC
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
fig_roc, ax_roc = plt.subplots()
ax_roc.plot(fpr, tpr, label=f'AUC = {auc:.3f}')
ax_roc.plot([0, 1], [0, 1], 'k--')
ax_roc.set_xlabel('False Positive Rate')
ax_roc.set_ylabel('True Positive Rate')
ax_roc.set_title('Krzywa ROC')
ax_roc.legend(loc='lower right')
st.pyplot(fig_roc)

# Tabela z wynikami
st.subheader("üìã Tabela predykcji")
st.markdown("Poni≈ºej znajdujƒÖ siƒô przyk≈Çadowe predykcje modelu na zbiorze testowym.")
# Przelicz prawdopodobie≈Ñstwo na score (0-100)
scorecard['Score'] = np.round(scorecard['Prawdopodobie≈Ñstwo'] * 100).astype(int)
# Recreate scorecard with index to easily merge with original features
scorecard_indexed = pd.DataFrame({
    'Prawdziwa klasa': y_test,
    'Prawdopodobie≈Ñstwo': y_pred_proba
}, index=y_test.index)
scorecard_indexed['Decyzja modelu'] = (scorecard_indexed['Prawdopodobie≈Ñstwo'] >= 0.5).astype(int)
scorecard_indexed['Score'] = np.round(scorecard_indexed['Prawdopodobie≈Ñstwo'] * 100).astype(int)

# Get original features for the test set using the index
original_features_test = df.loc[y_test.index, features_for_model]

# Combine Score, original features, and other scorecard columns
# Ensure 'Score' is the first column
scorecard_display = pd.concat([
    scorecard_indexed[['Score']],
    original_features_test,
    scorecard_indexed[['Prawdziwa klasa', 'Decyzja modelu']]
], axis=1)

# Display the enhanced scorecard
st.dataframe(scorecard_display, height=400, use_container_width=True, hide_index=True)


st.subheader("üßÆ Klasyczna karta scoringowa")


def build_scorecard(encoder, model, binning_tables):
    scorecard_rows = []

    # S≈Çownik: zmienna ‚Üí wsp√≥≈Çczynnik regresji
    coefs = dict(zip(encoder.cols, model.coef_[0]))

    for feature in encoder.cols:
        coef = coefs[feature]
        table = binning_tables[feature]

        for i, row in table.iterrows():
            bin_label = row["Przedzia≈Ç"]
            woe = row["WOE"]
            waga = round(coef * woe, 4)
            scorecard_rows.append({
                "Zmienna": feature,
                "Przedzia≈Ç": bin_label,
                "WOE": woe,
                "Wsp√≥≈Çczynnik RL": round(coef, 4),
                "Waga modelu (WOE √ó coef)": waga
            })

    scorecard_df = pd.DataFrame(scorecard_rows)
    return scorecard_df

scorecard_df = build_scorecard(encoder, model, binning_tables)

st.markdown("""
Tabela poni≈ºej przedstawia klasycznƒÖ kartƒô scoringowƒÖ:  
- Ka≈ºda zmienna zosta≈Ça podzielona na przedzia≈Çy (biny)  
- Dla ka≈ºdego przedzia≈Çu obliczono warto≈õƒá WOE  
- Nastƒôpnie wyliczono ‚Äûwagƒô‚Äù modelu: WOE √ó wsp√≥≈Çczynnik regresji  
Im wy≈ºsza warto≈õƒá ‚Äì tym bardziej pozytywny wp≈Çyw danego przedzia≈Çu na wynik modelu.
""")

st.dataframe(scorecard_df, use_container_width=True, hide_index=True)

@st.cache_data
def train_xgboost_model(df, target_col, features):
    X = df[features].copy()
    y = df[target_col]

    # Podzia≈Ç na trening/test
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.1, random_state=42, stratify=y
    )

    # Oblicz balans klas
    ratio = (y_train == 0).sum() / (y_train == 1).sum()

    model = xgb.XGBClassifier(
        n_estimators=60,               # wiƒôcej drzew
        max_depth=4,                    # kontrola z≈Ço≈ºono≈õci
        learning_rate=0.01,             # wolniejsze uczenie = dok≈Çadniejsze
        subsample=0.8,                  # losowe podzbiory danych
        colsample_bytree=0.8,           # losowy wyb√≥r cech
        scale_pos_weight=ratio,         # kompensacja niezbalansowanych klas
        use_label_encoder=False,
        eval_metric='auc',              # metryka na AUC
        random_state=42
    )

    model.fit(X_train, y_train)

    y_pred_proba = model.predict_proba(X_test)[:, 1]
    auc = roc_auc_score(y_test, y_pred_proba)
    gini = 2 * auc - 1

    return model, auc, gini, y_pred_proba, y_test, X_test

# =======================
# üîÆ Trening modelu XGBoost
# =======================

st.subheader("ü§ñ Model scoringowy XGBoost")

# Usu≈Ñ 'kwota_kredytu' z listy cech dla XGBoost
features_for_xgb_model = [f for f in features_for_model]

model_xgb, auc_xgb, gini_xgb, y_pred_proba_xgb, y_test_xgb, X_test_xgb = train_xgboost_model(
    df, "akceptacja_klienta", features_for_xgb_model
)

st.markdown(f"""
Model XGBoost zosta≈Ç wytrenowany na tych samych zmiennych co model WOE + RL.  
**Wyniki modelu:**
- **AUC**: {round(auc_xgb, 4)}
- **Gini**: {round(gini_xgb, 4)}
""")

# ROC
fpr_xgb, tpr_xgb, _ = roc_curve(y_test_xgb, y_pred_proba_xgb)
fig_roc_xgb, ax_roc_xgb = plt.subplots()
ax_roc_xgb.plot(fpr_xgb, tpr_xgb, label=f'AUC = {auc_xgb:.3f}')
ax_roc_xgb.plot([0, 1], [0, 1], 'k--')
ax_roc_xgb.set_xlabel('False Positive Rate')
ax_roc_xgb.set_ylabel('True Positive Rate')
ax_roc_xgb.set_title('Krzywa ROC ‚Äì XGBoost')
ax_roc_xgb.legend(loc='lower right')
st.pyplot(fig_roc_xgb)

# =======================
# üìã Scorecard XGBoost ‚Äì tabela predykcji
# =======================

st.subheader("üìã Tabela predykcji ‚Äì XGBoost")
st.markdown("Poni≈ºej znajdujƒÖ siƒô przyk≈Çadowe predykcje modelu XGBoost na zbiorze testowym.")

# Stw√≥rz DataFrame z wynikiem
scorecard_xgb_indexed = pd.DataFrame({
    'Prawdziwa klasa': y_test_xgb,
    'Prawdopodobie≈Ñstwo': y_pred_proba_xgb
}, index=y_test_xgb.index)

scorecard_xgb_indexed['Decyzja modelu'] = (scorecard_xgb_indexed['Prawdopodobie≈Ñstwo'] >= 0.5).astype(int)
scorecard_xgb_indexed['Score'] = np.round(scorecard_xgb_indexed['Prawdopodobie≈Ñstwo'] * 100).astype(int)

# Pobierz cechy oryginalne dla testu
original_features_test_xgb = df.loc[y_test_xgb.index, features_for_model]

# Po≈ÇƒÖcz Score, cechy i wyniki
scorecard_xgb_display = pd.concat([
    scorecard_xgb_indexed[['Score']],
    original_features_test_xgb,
    scorecard_xgb_indexed[['Prawdziwa klasa', 'Decyzja modelu']]
], axis=1)

# Wy≈õwietl tabelƒô
st.dataframe(scorecard_xgb_display, height=400, use_container_width=True, hide_index=True)




# ‚úÖ Nowy model XGBoost z dodatkowymi kolumnami WOE

def train_xgboost_model_with_woe(df, target_col, features, encoder):
    # Przygotowanie danych surowych i WOE
    X_raw = df[features].copy()
    X_woe = encoder.transform(df[features])

    # Z≈ÇƒÖcz dane: surowe + WOE (zmienne z sufiksem _woe)
    X_woe.columns = [f"{col}_woe" for col in X_woe.columns]
    X_combined = pd.concat([X_raw.reset_index(drop=True), X_woe.reset_index(drop=True)], axis=1)
    y = df[target_col].reset_index(drop=True)

    # Podzia≈Ç
    X_train, X_test, y_train, y_test = train_test_split(
        X_combined, y, test_size=0.1, random_state=42, stratify=y
    )

    ratio = (y_train == 0).sum() / (y_train == 1).sum()

    model = xgb.XGBClassifier(
        n_estimators=60,
        max_depth=4,
        learning_rate=0.01,
        subsample=0.8,
        colsample_bytree=0.8,
        scale_pos_weight=ratio,
        use_label_encoder=False,
        eval_metric='auc',
        random_state=42
    )

    model.fit(X_train, y_train)
    y_pred_proba = model.predict_proba(X_test)[:, 1]
    auc = roc_auc_score(y_test, y_pred_proba)
    gini = 2 * auc - 1

    return model, auc, gini, y_pred_proba, y_test, X_test, X_combined.columns.tolist()

# =======================
# ü§ñ Model XGBoost (surowe + WOE)
# =======================

st.subheader("ü§ñ Model XGBoost z dodatkowymi zmiennymi WOE")

model_xgb_woe, auc_xgb_woe, gini_xgb_woe, y_pred_xgb_woe, y_test_xgb_woe, X_test_xgb_woe, full_feature_list = train_xgboost_model_with_woe(
    df, "akceptacja_klienta", features_for_model, encoder
)

st.markdown(f"""
Model XGBoost zosta≈Ç wytrenowany na po≈ÇƒÖczonych zmiennych: surowych i ich odpowiednikach WOE.  
**Wyniki modelu:**
- **AUC**: {round(auc_xgb_woe, 4)}
- **Gini**: {round(gini_xgb_woe, 4)}
""")

fpr_woe, tpr_woe, _ = roc_curve(y_test_xgb_woe, y_pred_xgb_woe)
fig_roc_woe, ax_roc_woe = plt.subplots()
ax_roc_woe.plot(fpr_woe, tpr_woe, label=f'AUC = {auc_xgb_woe:.3f}')
ax_roc_woe.plot([0, 1], [0, 1], 'k--')
ax_roc_woe.set_xlabel('False Positive Rate')
ax_roc_woe.set_ylabel('True Positive Rate')
ax_roc_woe.set_title('Krzywa ROC ‚Äì XGBoost (z WOE)')
ax_roc_woe.legend(loc='lower right')
st.pyplot(fig_roc_woe)

# =======================
# üìã Tabela predykcji ‚Äì XGBoost z WOE
# =======================
st.subheader("üìã Tabela predykcji ‚Äì XGBoost (z WOE)")
st.markdown("Poni≈ºej znajdujƒÖ siƒô przyk≈Çadowe predykcje modelu XGBoost na zbiorze testowym z dodatkowymi cechami WOE.")

scorecard_xgb_woe_indexed = pd.DataFrame({
    'Prawdziwa klasa': y_test_xgb_woe,
    'Prawdopodobie≈Ñstwo': y_pred_xgb_woe
}, index=y_test_xgb_woe.index)

scorecard_xgb_woe_indexed['Decyzja modelu'] = (scorecard_xgb_woe_indexed['Prawdopodobie≈Ñstwo'] >= 0.5).astype(int)
scorecard_xgb_woe_indexed['Score'] = np.round(scorecard_xgb_woe_indexed['Prawdopodobie≈Ñstwo'] * 100).astype(int)

# Pobranie cech do scorecardu
original_features_test_woe = df.loc[y_test_xgb_woe.index, features_for_model].reset_index(drop=True)
woe_features_test = encoder.transform(df[features_for_model]).reset_index(drop=True).iloc[y_test_xgb_woe.index]
woe_features_test.columns = [f"{col}_woe" for col in woe_features_test.columns]

# ≈ÅƒÖczenie
scorecard_xgb_woe_display = pd.concat([
    scorecard_xgb_woe_indexed[['Score']],
    original_features_test_woe,
    woe_features_test,
    scorecard_xgb_woe_indexed[['Prawdziwa klasa', 'Decyzja modelu']]
], axis=1)

st.dataframe(scorecard_xgb_woe_display, height=400, use_container_width=True, hide_index=True)
